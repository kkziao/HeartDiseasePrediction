{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.dl_models import MLP, CombinedMLP\n",
    "from pipeline.preprocessing import feature_mfcc, feature_bandpower_struct, remove_high_frequencies\n",
    "from pipeline.dataloader import PhonocardiogramAudioDataset, PhonocardiogramByIDDatasetOnlyResult\n",
    "from pipeline.utils import compose_feature_label, audio_random_windowing\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import re, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = Path(\".\") / \"assets\" / \"the-circor-digiscope-phonocardiogram-dataset-1.0.3\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training on actual patient audio files\n",
    "\n",
    "def augmentation(data :np.ndarray, sr : int=4000, window_length_hz :int =200, window_len_sec :float=5.) ->np.ndarray:\n",
    "    x = data\n",
    "    # x = energy_band_augmentation_random_win(x, sr=sr, window_hz_length=window_length_hz)\n",
    "    # x = np.fft.ifft(x).real\n",
    "    x = audio_random_windowing(x, window_len_sec)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup = PhonocardiogramByIDDatasetOnlyResult(str(file / \"training_data.csv\"))\n",
    "\n",
    "# Feature functions\n",
    "features_fn = [\n",
    "    feature_mfcc, \n",
    "    # feature_chromagram, \n",
    "    # feature_melspectrogram,\n",
    "    feature_bandpower_struct(4000,200,0.7),\n",
    "    # NMF, # found -> takes around 0.1s per file\n",
    "    ]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dset_trans(f : str): # each takes ~0.1s\n",
    "\n",
    "    result = compose_feature_label(\n",
    "        f,\n",
    "        lookup, \n",
    "        features_fn,\n",
    "        lambda ary_data : remove_high_frequencies(augmentation(ary_data,4000,200,3.), sample_rate=4000,cutoff_frequency=450).real,\n",
    "        dim=2,\n",
    "        is_np=False\n",
    "    )\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "      \n",
    "def create_MLPs():\n",
    "    rand_sample = np.random.random((4000 * 10,)) # 10 sec sample for 4000sr\n",
    "    feature_space = [f_fn(rand_sample) for f_fn in features_fn]\n",
    "    \n",
    "    feat_sizes = [feat_matx.shape[0] for feat_matx in feature_space]\n",
    "    mlps = [\n",
    "        MLP([\n",
    "            feat_size, \n",
    "            64,\n",
    "            64 * 2, \n",
    "            1,] , torch.nn.ReLU)\n",
    "        for feat_size in feat_sizes\n",
    "    ]\n",
    "    \n",
    "    return mlps, feature_space\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feature_mfcc', 'feature_bandpower_struct.<locals>.feature_bandpower']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "        \n",
    "feature_based_mlps, example_feature = create_MLPs()\n",
    "combinedMLP = CombinedMLP(feature_based_mlps)\n",
    "    \n",
    "print([f.__qualname__ for f in features_fn])\n",
    "dset = PhonocardiogramAudioDataset(\n",
    "    file / \"clear_training_data\",\n",
    "    \".wav\",\n",
    "    \"*\", # Everything\n",
    "    transform=dset_trans,\n",
    "    balancing=True,\n",
    "    csvfile=str(file / \"training_data.csv\"),\n",
    "    shuffle=True,\n",
    ")\n",
    "    \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dset))\n",
    "test_size = len(dset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64,shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64,shuffle=False)\n",
    "\n",
    "# training\n",
    "combinedMLP.to(device)\n",
    "\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(combinedMLP.parameters(), lr=0.00001)\n",
    "\n",
    "num_epoch = 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:21<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.6722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:25<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Loss: 0.7437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Loss: 0.7043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:18<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Loss: 0.6821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:18<00:00,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Loss: 0.6995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from time import time\n",
    "\n",
    "combinedMLP.train()\n",
    "for epoch in range(num_epoch):\n",
    "    for X,y in tqdm(train_loader):\n",
    "\n",
    "        X = [x_sub.to(device) for x_sub in X]\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = combinedMLP(X)\n",
    "\n",
    "        # LATER\n",
    "        loss = criterion(out.squeeze(), y.float())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epoch}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4944],\n",
      "        [0.4588],\n",
      "        [0.4817],\n",
      "        [0.4712],\n",
      "        [0.5320],\n",
      "        [0.4783],\n",
      "        [0.5081],\n",
      "        [0.4868],\n",
      "        [0.4577],\n",
      "        [0.4575],\n",
      "        [0.5396],\n",
      "        [0.4973],\n",
      "        [0.4756],\n",
      "        [0.4551],\n",
      "        [0.4898],\n",
      "        [0.4766],\n",
      "        [0.5305],\n",
      "        [0.4907],\n",
      "        [0.4252],\n",
      "        [0.4564],\n",
      "        [0.5019],\n",
      "        [0.4743],\n",
      "        [0.4497],\n",
      "        [0.5045],\n",
      "        [0.5014],\n",
      "        [0.4706],\n",
      "        [0.5454],\n",
      "        [0.5246],\n",
      "        [0.4854],\n",
      "        [0.4894],\n",
      "        [0.4579],\n",
      "        [0.4686],\n",
      "        [0.4676],\n",
      "        [0.4767],\n",
      "        [0.5109],\n",
      "        [0.4959],\n",
      "        [0.4571],\n",
      "        [0.4753],\n",
      "        [0.4610],\n",
      "        [0.5017],\n",
      "        [0.4595],\n",
      "        [0.4334],\n",
      "        [0.5050],\n",
      "        [0.4730],\n",
      "        [0.4763],\n",
      "        [0.5021],\n",
      "        [0.4448],\n",
      "        [0.4606],\n",
      "        [0.4665],\n",
      "        [0.4242],\n",
      "        [0.4582],\n",
      "        [0.5090],\n",
      "        [0.4526],\n",
      "        [0.4904],\n",
      "        [0.5178],\n",
      "        [0.4567],\n",
      "        [0.5067],\n",
      "        [0.4635],\n",
      "        [0.4750],\n",
      "        [0.4493],\n",
      "        [0.5238],\n",
      "        [0.4800],\n",
      "        [0.5167],\n",
      "        [0.4581]]) tensor([1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (64) must match the size of tensor b (14) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(out, ytrain)\n\u001b[1;32m     13\u001b[0m     pred \u001b[38;5;241m=\u001b[39m (out\u001b[38;5;241m.\u001b[39msqueeze() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# Convert probabilities to binary predictions\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     accu \u001b[38;5;241m=\u001b[39m (\u001b[43mpred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mytrain\u001b[49m)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     15\u001b[0m     acc\u001b[38;5;241m.\u001b[39mappend(accu)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining set Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(acc)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(acc)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (64) must match the size of tensor b (14) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "combinedMLP.eval()\n",
    "acc = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for Xtrain, ytrain in tqdm(train_loader):\n",
    "        Xtrain = [x_sub.to(device) for x_sub in Xtrain]\n",
    "        ytrain = y.to(device)\n",
    "\n",
    "\n",
    "        out = combinedMLP(Xtrain)\n",
    "        print(out, ytrain)\n",
    "        pred = (out.squeeze() > 0.5).float()  # Convert probabilities to binary predictions\n",
    "        accu = (pred == ytrain).float().mean().item()\n",
    "        acc.append(accu)\n",
    "    print(f'Training set Accuracy: {sum(acc)/len(acc):.4f}')\n",
    "    \n",
    "    for Xtest, ytest in tqdm(test_loader):\n",
    "        Xtest = [x_sub.to(device) for x_sub in Xtest]\n",
    "        ytest = y.to(device)\n",
    "\n",
    "\n",
    "        out = combinedMLP(Xtest)\n",
    "        pred = (out.squeeze() > 0.5).float()  # Convert probabilities to binary predictions\n",
    "        accu = (pred == ytest).float().mean().item()\n",
    "        acc.append(accu)\n",
    "    print(f'Testing Accuracy: {sum(acc)/len(acc):.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
