{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.dl_models import MLP, CombinedMLP\n",
    "from pipeline.preprocessing import feature_mfcc, feature_bandpower_struct, remove_high_frequencies\n",
    "from pipeline.dataloader import PhonocardiogramAudioDataset, PhonocardiogramByIDDatasetOnlyResult\n",
    "from pipeline.utils import compose_feature_label, audio_random_windowing\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import re, random\n",
    "import os\n",
    "\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get label dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2530: 0, 9979: 0, 9983: 0, 13918: 0, 14241: 0, 14998: 0, 23625: 0, 24160: 0, 29045: 0, 29378: 0, 31737: 0, 33151: 0, 36327: 0, 38337: 0, 39043: 0, 39403: 0, 39456: 0, 40058: 0, 40798: 0, 40840: 0, 43852: 1, 44514: 0, 45843: 0, 46065: 0, 46532: 1, 46579: 0, 46778: 0, 47002: 0, 49558: 0, 49561: 0, 49562: 0, 49568: 1, 49572: 1, 49574: 0, 49577: 1, 49585: 0, 49595: 0, 49598: 1, 49607: 0, 49610: 0, 49618: 0, 49622: 0, 49627: 0, 49628: 0, 49630: 0, 49631: 1, 49638: 0, 49641: 0, 49653: 1, 49659: 0, 49661: 1, 49669: 0, 49678: 1, 49683: 0, 49687: 0, 49691: 0, 49704: 0, 49712: 0, 49719: 1, 49729: 0, 49735: 0, 49745: 0, 49748: 0, 49751: 0, 49754: 0, 49761: 0, 49776: 0, 49808: 1, 49821: 0, 49823: 0, 49824: 0, 49829: 0, 49832: 1, 49838: 0, 49839: 1, 49842: 0, 49850: 0, 49853: 1, 49854: 0, 49873: 0, 49876: 0, 49896: 1, 49897: 1, 49900: 0, 49930: 1, 49931: 1, 49946: 0, 49952: 1, 49959: 1, 49960: 1, 49963: 0, 49966: 0, 49968: 1, 49969: 1, 49970: 1, 49974: 1, 49978: 0, 49979: 1, 49980: 0, 49983: 1, 49986: 1, 49987: 1, 49988: 1, 49989: 0, 49990: 1, 49993: 1, 49994: 0, 49995: 1, 49998: 1, 49999: 1, 50001: 1, 50004: 1, 50005: 1, 50006: 1, 50007: 1, 50008: 1, 50009: 1, 50012: 0, 50014: 1, 50015: 0, 50017: 1, 50018: 0, 50023: 1, 50026: 1, 50027: 1, 50029: 1, 50030: 0, 50032: 1, 50034: 1, 50037: 1, 50043: 1, 50047: 1, 50048: 1, 50049: 0, 50053: 1, 50054: 0, 50056: 0, 50057: 1, 50061: 0, 50066: 0, 50067: 0, 50070: 0, 50072: 0, 50074: 1, 50075: 1, 50076: 0, 50077: 1, 50078: 0, 50079: 1, 50080: 0, 50085: 1, 50086: 1, 50089: 0, 50092: 1, 50094: 1, 50096: 0, 50099: 1, 50100: 0, 50103: 1, 50104: 1, 50105: 1, 50109: 1, 50111: 0, 50113: 1, 50115: 0, 50116: 1, 50117: 1, 50118: 1, 50119: 1, 50121: 1, 50122: 1, 50123: 0, 50125: 0, 50126: 1, 50127: 0, 50128: 0, 50129: 1, 50133: 1, 50136: 0, 50137: 1, 50138: 1, 50141: 1, 50142: 1, 50143: 1, 50145: 1, 50146: 1, 50149: 0, 50150: 0, 50151: 0, 50152: 0, 50153: 0, 50155: 0, 50159: 0, 50160: 1, 50161: 0, 50164: 1, 50165: 0, 50166: 0, 50168: 1, 50174: 0, 50204: 1, 50206: 0, 50207: 0, 50209: 0, 50210: 1, 50213: 1, 50214: 1, 50216: 0, 50217: 0, 50218: 1, 50219: 0, 50220: 0, 50221: 1, 50222: 1, 50225: 1, 50228: 1, 50229: 0, 50230: 1, 50231: 1, 50233: 0, 50238: 0, 50239: 1, 50241: 0, 50244: 0, 50247: 1, 50248: 0, 50249: 1, 50250: 1, 50251: 1, 50254: 1, 50255: 0, 50256: 1, 50258: 1, 50260: 1, 50261: 0, 50263: 1, 50264: 1, 50271: 1, 50272: 1, 50273: 1, 50275: 1, 50276: 1, 50277: 0, 50278: 1, 50280: 0, 50281: 0, 50284: 1, 50285: 0, 50289: 0, 50291: 0, 50295: 0, 50296: 0, 50297: 0, 50298: 1, 50299: 1, 50300: 0, 50303: 0, 50304: 1, 50306: 0, 50311: 1, 50312: 0, 50314: 0, 50316: 1, 50317: 1, 50318: 0, 50319: 0, 50321: 0, 50323: 0, 50325: 0, 50326: 0, 50327: 1, 50330: 0, 50331: 0, 50332: 0, 50334: 1, 50335: 0, 50336: 1, 50337: 1, 50339: 1, 50341: 0, 50342: 0, 50343: 0, 50345: 1, 50348: 0, 50349: 1, 50350: 0, 50352: 1, 50354: 0, 50359: 0, 50375: 0, 50379: 0, 50384: 1, 50385: 1, 50386: 0, 50388: 1, 50391: 1, 50393: 0, 50619: 0, 50620: 1, 50621: 0, 50624: 0, 50625: 0, 50626: 0, 50628: 0, 50629: 0, 50631: 0, 50635: 1, 50636: 0, 50639: 1, 50640: 0, 50641: 1, 50643: 0, 50644: 1, 50645: 1, 50646: 1, 50647: 1, 50649: 0, 50652: 0, 50654: 1, 50655: 0, 50656: 1, 50657: 1, 50658: 1, 50659: 0, 50661: 1, 50664: 0, 50665: 0, 50667: 1, 50668: 0, 50669: 1, 50671: 0, 50673: 0, 50676: 1, 50677: 0, 50678: 0, 50680: 0, 50685: 0, 50687: 1, 50688: 1, 50689: 0, 50690: 0, 50691: 1, 50693: 0, 50699: 1, 50704: 1, 50707: 1, 50708: 0, 50713: 1, 50715: 1, 50720: 0, 50721: 0, 50722: 1, 50723: 0, 50725: 0, 50727: 0, 50729: 1, 50731: 1, 50732: 0, 50734: 0, 50735: 1, 50736: 0, 50737: 1, 50738: 0, 50739: 0, 50740: 0, 50742: 0, 50743: 1, 50744: 0, 50746: 0, 50747: 1, 50748: 1, 50749: 1, 50751: 1, 50752: 1, 50753: 1, 50754: 1, 50756: 1, 50757: 1, 50758: 1, 50762: 1, 50763: 0, 50766: 1, 50768: 1, 50770: 1, 50771: 0, 50772: 1, 50773: 0, 50774: 0, 50776: 0, 50781: 1, 50782: 0, 50784: 1, 50787: 1, 50788: 1, 50789: 0, 50790: 0, 50793: 1, 50795: 1, 50796: 0, 50797: 0, 50798: 1, 50800: 1, 50802: 1, 50803: 0, 50805: 1, 50807: 0, 50812: 0, 50815: 1, 50818: 0, 50819: 1, 50820: 1, 50822: 1, 50826: 0, 50829: 1, 51064: 1, 51331: 0, 55945: 0, 57700: 0, 57706: 0, 59536: 0, 61117: 0, 61610: 0, 63456: 0, 63581: 0, 64256: 0, 64715: 1, 68175: 0, 68182: 0, 68186: 1, 68194: 0, 68204: 0, 68213: 1, 68219: 0, 68222: 0, 68255: 0, 68260: 1, 68269: 0, 68279: 0, 68292: 0, 68298: 0, 68303: 0, 68306: 0, 68316: 1, 68318: 0, 68327: 0, 68330: 0, 68337: 1, 68347: 0, 68359: 0, 68363: 0, 68368: 0, 68374: 0, 68377: 0, 68379: 0, 68394: 1, 68395: 1, 68404: 1, 68406: 0, 68407: 1, 68412: 1, 68413: 1, 68419: 0, 68423: 0, 68425: 0, 68427: 1, 68431: 1, 68432: 0, 68435: 0, 68436: 1, 68444: 0, 68449: 1, 68456: 0, 68460: 1, 68465: 0, 68470: 1, 68477: 1, 68478: 0, 68482: 0, 68484: 0, 68487: 0, 68498: 0, 68504: 1, 68532: 0, 68545: 0, 68556: 0, 68560: 0, 68567: 0, 68576: 0, 68582: 0, 68624: 0, 68632: 0, 68646: 0, 68659: 0, 68660: 1, 68682: 0, 68698: 0, 68702: 0, 68705: 1, 68708: 0, 68711: 0, 68737: 0, 68738: 0, 68740: 0, 68741: 0, 68752: 1, 68755: 0, 68756: 1, 68757: 1, 68796: 1, 68827: 0, 68831: 0, 68849: 0, 68857: 0, 68861: 0, 68864: 0, 68874: 0, 68886: 1, 68887: 0, 68888: 0, 68895: 0, 68901: 1, 68908: 0, 68909: 0, 68952: 0, 69060: 0, 69066: 0, 69067: 1, 69068: 0, 69079: 0, 69093: 0, 69095: 0, 69096: 0, 69106: 0, 69112: 0, 69120: 0, 69125: 0, 69129: 0, 69141: 0, 69144: 1, 69147: 0, 69152: 0, 69155: 0, 69159: 0, 69161: 1, 69174: 0, 69176: 0, 69188: 0, 70280: 0, 72283: 0, 72288: 0, 73316: 0, 73497: 0, 74417: 0, 74420: 0, 75440: 0, 76240: 0, 76758: 0, 77373: 0, 78280: 0, 78582: 0, 78592: 0, 80348: 0, 81035: 0, 81297: 1, 81501: 0, 81638: 0, 82275: 1, 83094: 0, 84687: 1, 84688: 1, 84689: 1, 84690: 0, 84692: 0, 84693: 0, 84695: 1, 84696: 0, 84697: 1, 84699: 0, 84702: 0, 84704: 0, 84706: 0, 84708: 0, 84709: 1, 84710: 0, 84711: 1, 84713: 0, 84714: 0, 84716: 0, 84718: 0, 84720: 0, 84721: 0, 84724: 1, 84725: 1, 84727: 1, 84730: 1, 84731: 1, 84732: 0, 84733: 0, 84734: 0, 84735: 1, 84736: 0, 84738: 1, 84740: 1, 84742: 1, 84743: 1, 84746: 1, 84747: 1, 84749: 1, 84750: 1, 84751: 0, 84753: 1, 84754: 1, 84755: 1, 84758: 1, 84760: 1, 84761: 1, 84762: 1, 84764: 1, 84765: 1, 84768: 1, 84769: 1, 84775: 1, 84776: 1, 84778: 1, 84779: 1, 84780: 1, 84784: 1, 84785: 1, 84786: 1, 84790: 1, 84793: 1, 84796: 0, 84798: 1, 84799: 1, 84802: 1, 84803: 0, 84804: 1, 84805: 1, 84807: 1, 84808: 1, 84809: 1, 84813: 1, 84814: 1, 84815: 1, 84822: 1, 84823: 1, 84824: 0, 84826: 1, 84829: 1, 84831: 1, 84834: 0, 84835: 1, 84837: 0, 84838: 1, 84839: 1, 84840: 0, 84851: 0, 84852: 1, 84853: 0, 84854: 0, 84855: 1, 84856: 0, 84857: 0, 84859: 1, 84861: 1, 84863: 0, 84864: 1, 84865: 0, 84866: 1, 84868: 1, 84870: 0, 84874: 1, 84875: 1, 84876: 0, 84877: 1, 84878: 1, 84879: 1, 84881: 1, 84882: 0, 84883: 1, 84884: 1, 84885: 0, 84886: 1, 84887: 1, 84890: 1, 84892: 1, 84893: 1, 84894: 1, 84896: 1, 84900: 1, 84912: 1, 84917: 1, 84918: 1, 84919: 1, 84920: 1, 84921: 1, 84922: 1, 84923: 1, 84928: 1, 84930: 1, 84931: 0, 84933: 1, 84934: 0, 84935: 1, 84936: 1, 84937: 1, 84939: 1, 84942: 1, 84945: 1, 84946: 1, 84947: 0, 84949: 0, 84950: 0, 84952: 1, 84957: 1, 84960: 1, 84961: 1, 84962: 1, 84965: 0, 84966: 1, 84969: 0, 84970: 1, 84971: 1, 84973: 1, 84974: 1, 84976: 1, 84977: 1, 84978: 1, 84982: 1, 84983: 1, 84984: 0, 84985: 1, 84986: 1, 84987: 1, 84988: 1, 84990: 1, 84991: 1, 84992: 1, 84993: 0, 84994: 0, 84995: 1, 84996: 0, 85000: 1, 85002: 0, 85004: 0, 85010: 0, 85011: 1, 85012: 0, 85018: 0, 85019: 0, 85020: 0, 85023: 1, 85024: 0, 85026: 0, 85027: 1, 85028: 1, 85029: 1, 85030: 0, 85031: 0, 85033: 1, 85034: 0, 85035: 1, 85036: 0, 85037: 0, 85038: 0, 85042: 0, 85043: 1, 85044: 1, 85046: 1, 85048: 1, 85052: 0, 85053: 1, 85055: 0, 85057: 0, 85062: 1, 85063: 1, 85064: 1, 85066: 1, 85069: 0, 85075: 1, 85076: 1, 85077: 1, 85079: 0, 85080: 0, 85081: 0, 85084: 1, 85086: 1, 85087: 0, 85090: 1, 85091: 1, 85093: 1, 85094: 1, 85096: 1, 85099: 1, 85100: 1, 85102: 1, 85103: 1, 85105: 1, 85108: 0, 85109: 1, 85110: 1, 85112: 1, 85113: 1, 85114: 1, 85115: 1, 85116: 0, 85118: 1, 85119: 0, 85121: 1, 85122: 1, 85123: 1, 85124: 1, 85127: 0, 85128: 1, 85131: 1, 85132: 0, 85133: 0, 85134: 1, 85135: 1, 85136: 1, 85139: 0, 85140: 1, 85143: 1, 85144: 0, 85145: 0, 85147: 1, 85148: 1, 85150: 1, 85151: 1, 85152: 1, 85153: 1, 85154: 1, 85155: 1, 85157: 1, 85159: 1, 85161: 0, 85162: 0, 85163: 0, 85164: 1, 85165: 0, 85166: 1, 85167: 1, 85168: 1, 85169: 0, 85172: 0, 85174: 0, 85175: 1, 85176: 1, 85180: 1, 85181: 1, 85182: 1, 85184: 1, 85186: 1, 85192: 0, 85196: 1, 85197: 1, 85198: 0, 85199: 0, 85202: 0, 85203: 1, 85207: 0, 85210: 1, 85212: 1, 85213: 0, 85214: 1, 85216: 1, 85217: 1, 85219: 0, 85222: 1, 85225: 0, 85226: 1, 85227: 0, 85229: 1, 85230: 1, 85234: 1, 85235: 1, 85236: 0, 85239: 0, 85240: 1, 85241: 1, 85242: 1, 85243: 0, 85244: 0, 85245: 1, 85246: 1, 85247: 0, 85249: 1, 85250: 1, 85252: 1, 85253: 0, 85258: 1, 85259: 0, 85261: 0, 85262: 0, 85264: 1, 85265: 1, 85269: 1, 85270: 0, 85276: 0, 85277: 1, 85278: 0, 85279: 0, 85282: 1, 85285: 1, 85286: 1, 85287: 1, 85288: 1, 85293: 0, 85294: 0, 85296: 0, 85299: 1, 85300: 1, 85301: 1, 85305: 0, 85306: 0, 85308: 1, 85312: 1, 85313: 1, 85315: 0, 85316: 1, 85317: 1, 85319: 0, 85321: 1, 85322: 1, 85323: 1, 85326: 1, 85327: 1, 85328: 1, 85329: 1, 85331: 1, 85332: 1, 85334: 1, 85335: 1, 85336: 1, 85337: 1, 85338: 1, 85339: 1, 85340: 1, 85341: 1, 85343: 0, 85345: 1, 85349: 1}\n"
     ]
    }
   ],
   "source": [
    "dataset_info = pd.read_csv('assets/the-circor-digiscope-phonocardiogram-dataset-1.0.3/training_data.csv')\n",
    "\n",
    "outcome_mapping = {'Normal': 1, 'Abnormal': 0}\n",
    "dataset_info['Mapped_Outcome'] = dataset_info['Outcome'].map(outcome_mapping)\n",
    "y_dict = dict(zip(dataset_info['Patient ID'], dataset_info['Mapped_Outcome']))\n",
    "\n",
    "print(y_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['50336_MV.wav',\n",
       " '50048_TV.wav',\n",
       " '68347_TV.wav',\n",
       " '50619_TV.wav',\n",
       " '84960_MV.wav']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_files_by_keywords_and_extension(folder_path, keywords, extension):\n",
    "    filtered_files = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if any(keyword in filename for keyword in keywords) and filename.endswith(extension):\n",
    "            filtered_files.append(filename)\n",
    "    return filtered_files\n",
    "\n",
    "folder_path = 'assets/the-circor-digiscope-phonocardiogram-dataset-1.0.3/training_data'\n",
    "keywords = ['TV','AV','PV','MV']\n",
    "extension = '.wav'\n",
    "\n",
    "filtered_files = filter_files_by_keywords_and_extension(folder_path, keywords, extension)\n",
    "filtered_files[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import librosa\n",
    "import torch\n",
    "\n",
    "# Load the audio file\n",
    "def get_features(file_path):\n",
    "    sound, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "    # Normalize the audio\n",
    "    sound = sound / np.max(np.abs(sound))\n",
    "\n",
    "\n",
    "    window_length_sec = 5\n",
    "    window_length_samples = window_length_sec * sr\n",
    "    windows = []\n",
    "    for start in range(0, len(sound), window_length_samples):\n",
    "        end = start + window_length_samples\n",
    "        if end > len(sound):\n",
    "            break\n",
    "        window = sound[start:end]\n",
    "        windows.append(window)\n",
    "\n",
    "    spectrograms = []\n",
    "    for window in windows:\n",
    "        S = librosa.stft(window, n_fft=2048, hop_length=512)\n",
    "        S_db = librosa.amplitude_to_db(np.abs(S), ref=np.max)\n",
    "        spectrograms.append(S_db)\n",
    "    \n",
    "    return spectrograms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'assets/the-circor-digiscope-phonocardiogram-dataset-1.0.3/training_data/2530_AV.wav'\n",
    "a = get_features(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3159/3159 [00:10<00:00, 290.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import soundfile\n",
    "import re, os\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "def load_data(filtered_files):\n",
    "    X, y = [], []\n",
    "    count = 0\n",
    "    for file in tqdm(filtered_files):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        features = get_features(file_path)\n",
    "        file_number = int(re.match(r'^([^_]*)', file)[1])\n",
    "        label = y_dict[file_number]\n",
    "\n",
    "        for feature in features:\n",
    "            X.append(feature)\n",
    "            y.append(label)\n",
    "        count += 1\n",
    "\n",
    "    print()\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "features, labels = load_data(filtered_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of data features:  12929\n",
      "the number of data labels:  12929\n"
     ]
    }
   ],
   "source": [
    "print(\"the number of data features: \", len(features))\n",
    "print(\"the number of data labels: \", len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (10343, 1025, 40)\n",
      "y_train.shape (10343,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X_train.shape\", X_train.shape)\n",
    "print('y_train.shape', y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 424063000 into shape (10343,1025,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Reshape X_train for 1D CNN\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m X_train_reshaped \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m     29\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train_reshaped, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 424063000 into shape (10343,1025,1)"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layer\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "\n",
    "# Add max pooling layer\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# Flatten the output\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add dense layers\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.005)  # Specify learning rate within Adam optimizer\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy', 'recall'])\n",
    "\n",
    "# Reshape X_train for 1D CNN\n",
    "X_train_reshaped = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.5335 - loss: 0.6865 - recall: 0.7928\n",
      "Evaluation Results:\n",
      "Test Loss: 0.6957356333732605\n",
      "Test Accuracy: 0.5228758454322815\n"
     ]
    }
   ],
   "source": [
    "# Reshape X_test for evaluation\n",
    "X_test_reshaped = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation_results = model.evaluate(X_test_reshaped, y_test)\n",
    "\n",
    "# Extracting individual evaluation metrics\n",
    "loss = evaluation_results[0]\n",
    "accuracy = evaluation_results[1]\n",
    "\n",
    "# Printing evaluation results\n",
    "print(\"Evaluation Results:\")\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5030 - loss: 3.1771 - recall: 0.5091 - val_accuracy: 0.5000 - val_loss: 0.7436 - val_recall: 1.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5205 - loss: 0.7303 - recall: 0.5952 - val_accuracy: 0.5122 - val_loss: 0.6921 - val_recall: 0.9184\n",
      "Epoch 3/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5351 - loss: 0.7010 - recall: 0.5849 - val_accuracy: 0.5000 - val_loss: 0.6922 - val_recall: 1.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5177 - loss: 0.6953 - recall: 0.7327 - val_accuracy: 0.5000 - val_loss: 0.6921 - val_recall: 1.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5219 - loss: 0.6915 - recall: 0.7292 - val_accuracy: 0.5653 - val_loss: 0.6901 - val_recall: 0.2408\n",
      "Epoch 6/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5142 - loss: 0.6930 - recall: 0.5279 - val_accuracy: 0.5878 - val_loss: 0.6908 - val_recall: 0.7184\n",
      "Epoch 7/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5424 - loss: 0.6926 - recall: 0.4265 - val_accuracy: 0.5000 - val_loss: 0.6926 - val_recall: 1.0000\n",
      "Epoch 8/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5046 - loss: 0.6943 - recall: 0.8870 - val_accuracy: 0.5020 - val_loss: 0.6921 - val_recall: 1.0000\n",
      "Epoch 9/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5078 - loss: 0.6897 - recall: 0.8542 - val_accuracy: 0.5000 - val_loss: 0.6891 - val_recall: 1.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5122 - loss: 0.6964 - recall: 0.4775 - val_accuracy: 0.5327 - val_loss: 0.6840 - val_recall: 0.9673\n",
      "Epoch 11/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5387 - loss: 0.6944 - recall: 0.6204 - val_accuracy: 0.5510 - val_loss: 0.6897 - val_recall: 0.8286\n",
      "Epoch 12/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5306 - loss: 0.6892 - recall: 0.4718 - val_accuracy: 0.5612 - val_loss: 0.6866 - val_recall: 0.7224\n",
      "Epoch 13/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5342 - loss: 0.6904 - recall: 0.5168 - val_accuracy: 0.5837 - val_loss: 0.6852 - val_recall: 0.7592\n",
      "Epoch 14/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5337 - loss: 0.6867 - recall: 0.4091 - val_accuracy: 0.5000 - val_loss: 0.6859 - val_recall: 1.0000\n",
      "Epoch 15/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4977 - loss: 0.6925 - recall: 0.4791 - val_accuracy: 0.5673 - val_loss: 0.6834 - val_recall: 0.8245\n",
      "Epoch 16/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5443 - loss: 0.6885 - recall: 0.5781 - val_accuracy: 0.5918 - val_loss: 0.6842 - val_recall: 0.5469\n",
      "Epoch 17/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5316 - loss: 0.6869 - recall: 0.4406 - val_accuracy: 0.6000 - val_loss: 0.6805 - val_recall: 0.5673\n",
      "Epoch 18/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5601 - loss: 0.6822 - recall: 0.4570 - val_accuracy: 0.5776 - val_loss: 0.6765 - val_recall: 0.8898\n",
      "Epoch 19/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5198 - loss: 0.6924 - recall: 0.3372 - val_accuracy: 0.5714 - val_loss: 0.6802 - val_recall: 0.4980\n",
      "Epoch 20/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5240 - loss: 0.6901 - recall: 0.3811 - val_accuracy: 0.5000 - val_loss: 0.6841 - val_recall: 0.9918\n",
      "Epoch 21/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5490 - loss: 0.6888 - recall: 0.5721 - val_accuracy: 0.5714 - val_loss: 0.6808 - val_recall: 0.2286\n",
      "Epoch 22/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5589 - loss: 0.6851 - recall: 0.3597 - val_accuracy: 0.5653 - val_loss: 0.6850 - val_recall: 0.2082\n",
      "Epoch 23/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5412 - loss: 0.6836 - recall: 0.3500 - val_accuracy: 0.5878 - val_loss: 0.6693 - val_recall: 0.8571\n",
      "Epoch 24/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5673 - loss: 0.6805 - recall: 0.5159 - val_accuracy: 0.5612 - val_loss: 0.6803 - val_recall: 0.1673\n",
      "Epoch 25/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5476 - loss: 0.6838 - recall: 0.3069 - val_accuracy: 0.5612 - val_loss: 0.6769 - val_recall: 0.1755\n",
      "Epoch 26/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5318 - loss: 0.6888 - recall: 0.4259 - val_accuracy: 0.5653 - val_loss: 0.6826 - val_recall: 0.1796\n",
      "Epoch 27/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5206 - loss: 0.6863 - recall: 0.4118 - val_accuracy: 0.5918 - val_loss: 0.6675 - val_recall: 0.6286\n",
      "Epoch 28/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5369 - loss: 0.6840 - recall: 0.4135 - val_accuracy: 0.6163 - val_loss: 0.6740 - val_recall: 0.7224\n",
      "Epoch 29/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5865 - loss: 0.6794 - recall: 0.4857 - val_accuracy: 0.5959 - val_loss: 0.6746 - val_recall: 0.5020\n",
      "Epoch 30/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5733 - loss: 0.6753 - recall: 0.3813 - val_accuracy: 0.5653 - val_loss: 0.6768 - val_recall: 0.1796\n",
      "Epoch 31/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5168 - loss: 0.6868 - recall: 0.3078 - val_accuracy: 0.5735 - val_loss: 0.6811 - val_recall: 0.2000\n",
      "Epoch 32/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5445 - loss: 0.6833 - recall: 0.1451 - val_accuracy: 0.6082 - val_loss: 0.6650 - val_recall: 0.6531\n",
      "Epoch 33/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5754 - loss: 0.6798 - recall: 0.5049 - val_accuracy: 0.5857 - val_loss: 0.6802 - val_recall: 0.2327\n",
      "Epoch 34/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5358 - loss: 0.6887 - recall: 0.3284 - val_accuracy: 0.5714 - val_loss: 0.6654 - val_recall: 0.4163\n",
      "Epoch 35/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5587 - loss: 0.6907 - recall: 0.4522 - val_accuracy: 0.5429 - val_loss: 0.6769 - val_recall: 0.3469\n",
      "Epoch 36/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5552 - loss: 0.6774 - recall: 0.4842 - val_accuracy: 0.5449 - val_loss: 0.6806 - val_recall: 0.1224\n",
      "Epoch 37/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5557 - loss: 0.6816 - recall: 0.2816 - val_accuracy: 0.6020 - val_loss: 0.6647 - val_recall: 0.5102\n",
      "Epoch 38/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5549 - loss: 0.6803 - recall: 0.4341 - val_accuracy: 0.6122 - val_loss: 0.6709 - val_recall: 0.3959\n",
      "Epoch 39/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5554 - loss: 0.6814 - recall: 0.2959 - val_accuracy: 0.6102 - val_loss: 0.6690 - val_recall: 0.4939\n",
      "Epoch 40/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5601 - loss: 0.6762 - recall: 0.4484 - val_accuracy: 0.6122 - val_loss: 0.6705 - val_recall: 0.3755\n",
      "Epoch 41/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5655 - loss: 0.6816 - recall: 0.4172 - val_accuracy: 0.5755 - val_loss: 0.6714 - val_recall: 0.2490\n",
      "Epoch 42/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5584 - loss: 0.6813 - recall: 0.3791 - val_accuracy: 0.5102 - val_loss: 0.6939 - val_recall: 0.9673\n",
      "Epoch 43/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5660 - loss: 0.6980 - recall: 0.5084 - val_accuracy: 0.5408 - val_loss: 0.6824 - val_recall: 0.0898\n",
      "Epoch 44/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5365 - loss: 0.6863 - recall: 0.2013 - val_accuracy: 0.5776 - val_loss: 0.6706 - val_recall: 0.2694\n",
      "Epoch 45/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5586 - loss: 0.6844 - recall: 0.4464 - val_accuracy: 0.5857 - val_loss: 0.6746 - val_recall: 0.2531\n",
      "Epoch 46/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5612 - loss: 0.6825 - recall: 0.3980 - val_accuracy: 0.5857 - val_loss: 0.6696 - val_recall: 0.3020\n",
      "Epoch 47/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5644 - loss: 0.6781 - recall: 0.4112 - val_accuracy: 0.5857 - val_loss: 0.6729 - val_recall: 0.2857\n",
      "Epoch 48/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5719 - loss: 0.6770 - recall: 0.4783 - val_accuracy: 0.6020 - val_loss: 0.6712 - val_recall: 0.3551\n",
      "Epoch 49/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5539 - loss: 0.6769 - recall: 0.3666 - val_accuracy: 0.5367 - val_loss: 0.6795 - val_recall: 0.0939\n",
      "Epoch 50/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5482 - loss: 0.6790 - recall: 0.2814 - val_accuracy: 0.5878 - val_loss: 0.6647 - val_recall: 0.3878\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1216</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">155,776</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1216\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m155,776\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">486,725</span> (1.86 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m486,725\u001b[0m (1.86 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">162,241</span> (633.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m162,241\u001b[0m (633.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">324,484</span> (1.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m324,484\u001b[0m (1.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layers\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Flatten the output\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add dense layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.001)  # Adjusted learning rate\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy', 'recall'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train, epochs=50, batch_size=64, validation_split=0.2)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 0.6282 - loss: 0.6685 - recall: 0.4104\n",
      "Evaluation Results:\n",
      "Test Loss: 0.6727418303489685\n",
      "Test Accuracy: 0.6127451062202454\n"
     ]
    }
   ],
   "source": [
    "# Reshape X_test for evaluation\n",
    "X_test_reshaped = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation_results = model.evaluate(X_test_reshaped, y_test)\n",
    "\n",
    "# Extracting individual evaluation metrics\n",
    "loss = evaluation_results[0]\n",
    "accuracy = evaluation_results[1]\n",
    "\n",
    "# Printing evaluation results\n",
    "print(\"Evaluation Results:\")\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
